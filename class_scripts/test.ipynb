{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#script per il testing di dataset_emtropy sul dataset corrente\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import math\n",
    "df = pd.read_csv(\"../DatasetClientClustering.csv\", \n",
    "                 engine='c', \n",
    "                 sep=',', \n",
    "                 encoding='latin-1')\n",
    "df = df.drop(df.columns[list(np.arange(8))], axis=1)\n",
    "df = df.drop(columns=[\"ClientID\", \"Prov\", \"ClientDateStart\", \"AuM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5.850377914779357\n"
    }
   ],
   "source": [
    "#distanza fra due righe del dataframe\n",
    "row1 = df.iloc[3]\n",
    "row2 = df.iloc[5]\n",
    "print(np.linalg.norm(row1 - row2))\n",
    "\n",
    "def dist_measure(x1, x2):\n",
    "    return np.linalg.norm(x1- x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#matrice delle distanze\n",
    "#distanza fra due righe del dataframe\n",
    "def dist_matrix(df):\n",
    "    df = df.reset_index(drop = True)\n",
    "    MATRIX = [\n",
    "        [\n",
    "            dist_measure(row1, row2) \n",
    "            for index1, row1 in df.iterrows()\n",
    "        ]\n",
    "        for index2, row2 in df.iterrows()\n",
    "    ]\n",
    "    return MATRIX\n",
    "dist = np.matrix( dist_matrix( df.sample(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "matrix([[1.        , 0.57717214, 0.7450751 , 0.26120699, 0.30901759,\n         0.51455044, 0.63526537, 0.5219796 , 0.4901882 , 0.62467662],\n        [0.57717214, 1.        , 0.53272737, 0.43879825, 0.50508457,\n         0.31532535, 0.78788364, 0.87186029, 0.83864958, 0.40302924],\n        [0.7450751 , 0.53272737, 1.        , 0.23749933, 0.27478581,\n         0.57764736, 0.62663747, 0.48685536, 0.45893061, 0.74903003],\n        [0.26120699, 0.43879825, 0.23749933, 1.        , 0.81520559,\n         0.14251528, 0.35697973, 0.46818993, 0.51465316, 0.1809439 ],\n        [0.30901759, 0.50508457, 0.27478581, 0.81520559, 1.        ,\n         0.1673427 , 0.4045283 , 0.52765665, 0.58401477, 0.21029025],\n        [0.51455044, 0.31532535, 0.57764736, 0.14251528, 0.1673427 ,\n         1.        , 0.36622483, 0.28620209, 0.27162482, 0.75240918],\n        [0.63526537, 0.78788364, 0.62663747, 0.35697973, 0.4045283 ,\n         0.36622483, 1.        , 0.75717559, 0.68565475, 0.47464376],\n        [0.5219796 , 0.87186029, 0.48685536, 0.46818993, 0.52765665,\n         0.28620209, 0.75717559, 1.        , 0.86031196, 0.36871204],\n        [0.4901882 , 0.83864958, 0.45893061, 0.51465316, 0.58401477,\n         0.27162482, 0.68565475, 0.86031196, 1.        , 0.34794666],\n        [0.4901882 , 0.83864958, 0.45893061, 0.51465316, 0.58401477,\n         0.27162482, 0.68565475, 0.86031196, 1.        , 0.34794666]])"
     },
     "metadata": {},
     "execution_count": 88
    }
   ],
   "source": [
    "#definisco una funzione che data una una matrice delle distanze definisce una matrice delle\n",
    "#similarità, con misura esponenziale\n",
    "def sim_matrix(dist_matrix):\n",
    "    #calcolo di alpha \n",
    "    alpha = -math.log(0.5) / np.matrix.mean(dist_matrix)\n",
    "    #funzione per calcolo della similarità dalla distanza\n",
    "    def sim(dist_value, alpha):\n",
    "        return math.exp(-alpha * dist_value)\n",
    "    vsim = np.vectorize(sim)\n",
    "    #sostituisco ogni elemento della matrice con la similarità\n",
    "    MATRIX = vsim(dist_matrix, alpha)\n",
    "    return MATRIX\n",
    "simp = sim_matrix(dist)\n",
    "simp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-39.47384017867732"
     },
     "metadata": {},
     "execution_count": 122
    }
   ],
   "source": [
    "#definisco una funzione che data una matrice di similarità calcola l'entropia del dataset\n",
    "def dataset_entropy(sim_matrix):\n",
    "    #funzione per trasformare valori di similarità in valori di entropia\n",
    "    def sim_to_entropy(sv):\n",
    "        if sv != 1:\n",
    "            sv = (sv * math.log2(sv)) + ((1-sv)*math.log2(1-sv))\n",
    "            return sv\n",
    "        else:\n",
    "            return float('nan')\n",
    "    entropies = [sim_to_entropy(x) for x in np.nditer(sim_matrix)]\n",
    "    return np.nansum(entropies)/2\n",
    "dataset_entropy(simp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.0\n0.5771721370872664\n0.7450750981320657\n0.26120699338650494\n0.3090175876499527\n0.5145504366767442\n0.6352653668864211\n0.5219795955085119\n0.4901882036981718\n0.6246766173256253\n0.5771721370872664\n1.0\n0.5327273734122255\n0.43879824596405187\n0.5050845684606289\n0.315325352331012\n0.7878836434918319\n0.8718602934512781\n0.8386495755593573\n0.40302924212189006\n0.7450750981320657\n0.5327273734122255\n1.0\n0.2374993324659334\n0.27478580695684185\n0.5776473591494968\n0.626637469653655\n0.4868553648338569\n0.45893061388998635\n0.749030025122585\n0.26120699338650494\n0.43879824596405187\n0.2374993324659334\n1.0\n0.8152055923075221\n0.14251527815148465\n0.3569797284359603\n0.4681899317611342\n0.5146531574943836\n0.18094389635558528\n0.3090175876499527\n0.5050845684606289\n0.27478580695684185\n0.8152055923075221\n1.0\n0.16734270220850625\n0.40452829863651085\n0.5276566512212233\n0.58401477231922\n0.210290245757699\n0.5145504366767442\n0.315325352331012\n0.5776473591494968\n0.14251527815148465\n0.16734270220850625\n1.0\n0.3662248252292247\n0.2862020854010156\n0.2716248229045659\n0.7524091834455123\n0.6352653668864211\n0.7878836434918319\n0.626637469653655\n0.3569797284359603\n0.40452829863651085\n0.3662248252292247\n1.0\n0.7571755883765703\n0.6856547460766506\n0.47464376439934514\n0.5219795955085119\n0.8718602934512781\n0.4868553648338569\n0.4681899317611342\n0.5276566512212233\n0.2862020854010156\n0.7571755883765703\n1.0\n0.860311962391334\n0.3687120413141199\n0.4901882036981718\n0.8386495755593573\n0.45893061388998635\n0.5146531574943836\n0.58401477231922\n0.2716248229045659\n0.6856547460766506\n0.860311962391334\n1.0\n0.3479466553595227\n0.4901882036981718\n0.8386495755593573\n0.45893061388998635\n0.5146531574943836\n0.58401477231922\n0.2716248229045659\n0.6856547460766506\n0.860311962391334\n1.0\n0.3479466553595227\n"
    }
   ],
   "source": [
    "def sim_to_entropy(sv):\n",
    "        if sv != 1:\n",
    "            sv = (sv * math.log2(sv)) + ((1-sv)*math.log2(1-sv))\n",
    "        else:\n",
    "            sv = 0\n",
    "        print(sv)\n",
    "        return(sv)\n",
    "\n",
    "for i in np.nditer(simp):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "path = \"/home/davidebadalotti/DATA-SCIENCE-1/data-science-lab/advise_only/class_scripts/\"\n",
    "os.chdir(path)\n",
    "from entropy_selection_class import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-41.121448013396204"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "First_test = feature_ranking(df.sample(10))\n",
    "First_test.dist_matrix()\n",
    "First_test.set_alpha()\n",
    "First_test.sim_matrix()\n",
    "First_test.simmatrix_entropy()\n",
    "First_test.E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "['RiskPropension',\n 'PortfolioRisk',\n 'ClientInvestmentHorizon',\n 'PortfolioHorizon',\n 'ClientKnowledgeExperience',\n 'ClientPotentialIndex',\n 'IncomeHighLow',\n 'Sex',\n 'Age',\n 'IncomeNeed',\n 'LongTermCareNeed',\n 'ProtectionNeed',\n 'PensionNeed',\n 'InheritanceIndex',\n 'PanicMood',\n 'NoTrustInBanks',\n 'BondInvestments',\n 'EquityInvestments',\n 'MoneyMarketInvestments',\n 'OtherInvestments',\n 'Cash']"
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "Second_test = feature_ranking(df.sample(10))\n",
    "Second_test.complete()\n",
    "list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "features: \n\t\t RiskPropension\n\t\t PortfolioRisk\n\t\t ClientInvestmentHorizon\n\t\t PortfolioHorizon\n\t\t ClientKnowledgeExperience\n\t\t ClientPotentialIndex\n\t\t IncomeHighLow\n\t\t Sex\n\t\t Age\n\t\t IncomeNeed\n\t\t LongTermCareNeed\n\t\t ProtectionNeed\n\t\t PensionNeed\n\t\t InheritanceIndex\n\t\t PanicMood\n\t\t NoTrustInBanks\n\t\t BondInvestments\n\t\t EquityInvestments\n\t\t MoneyMarketInvestments\n\t\t OtherInvestments\n\t\t Cash\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                           ranking      entropy\nfeature                                        \nPortfolioRisk                    0 -4298.424105\nOtherInvestments                 1 -4298.377961\nRiskPropension                   2 -4298.366447\nPanicMood                        3 -4298.334113\nMoneyMarketInvestments           4 -4298.228548\nInheritanceIndex                 5 -4298.209441\nPensionNeed                      6 -4298.123653\nProtectionNeed                   7 -4298.115248\nIncomeNeed                       8 -4298.086246\nClientKnowledgeExperience        9 -4298.068628\nClientPotentialIndex            10 -4297.959174\nEquityInvestments               11 -4297.876698\nBondInvestments                 12 -4297.699693\nCash                            13 -4297.649937\nLongTermCareNeed                14 -4297.644149\nNoTrustInBanks                  15 -4297.193057\nIncomeHighLow                   16 -4297.080552\nSex                             17 -4294.237978\nPortfolioHorizon                18 -4261.180163\nAge                             19 -4138.979040\nClientInvestmentHorizon         20 -4107.523616",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ranking</th>\n      <th>entropy</th>\n    </tr>\n    <tr>\n      <th>feature</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>PortfolioRisk</td>\n      <td>0</td>\n      <td>-4298.424105</td>\n    </tr>\n    <tr>\n      <td>OtherInvestments</td>\n      <td>1</td>\n      <td>-4298.377961</td>\n    </tr>\n    <tr>\n      <td>RiskPropension</td>\n      <td>2</td>\n      <td>-4298.366447</td>\n    </tr>\n    <tr>\n      <td>PanicMood</td>\n      <td>3</td>\n      <td>-4298.334113</td>\n    </tr>\n    <tr>\n      <td>MoneyMarketInvestments</td>\n      <td>4</td>\n      <td>-4298.228548</td>\n    </tr>\n    <tr>\n      <td>InheritanceIndex</td>\n      <td>5</td>\n      <td>-4298.209441</td>\n    </tr>\n    <tr>\n      <td>PensionNeed</td>\n      <td>6</td>\n      <td>-4298.123653</td>\n    </tr>\n    <tr>\n      <td>ProtectionNeed</td>\n      <td>7</td>\n      <td>-4298.115248</td>\n    </tr>\n    <tr>\n      <td>IncomeNeed</td>\n      <td>8</td>\n      <td>-4298.086246</td>\n    </tr>\n    <tr>\n      <td>ClientKnowledgeExperience</td>\n      <td>9</td>\n      <td>-4298.068628</td>\n    </tr>\n    <tr>\n      <td>ClientPotentialIndex</td>\n      <td>10</td>\n      <td>-4297.959174</td>\n    </tr>\n    <tr>\n      <td>EquityInvestments</td>\n      <td>11</td>\n      <td>-4297.876698</td>\n    </tr>\n    <tr>\n      <td>BondInvestments</td>\n      <td>12</td>\n      <td>-4297.699693</td>\n    </tr>\n    <tr>\n      <td>Cash</td>\n      <td>13</td>\n      <td>-4297.649937</td>\n    </tr>\n    <tr>\n      <td>LongTermCareNeed</td>\n      <td>14</td>\n      <td>-4297.644149</td>\n    </tr>\n    <tr>\n      <td>NoTrustInBanks</td>\n      <td>15</td>\n      <td>-4297.193057</td>\n    </tr>\n    <tr>\n      <td>IncomeHighLow</td>\n      <td>16</td>\n      <td>-4297.080552</td>\n    </tr>\n    <tr>\n      <td>Sex</td>\n      <td>17</td>\n      <td>-4294.237978</td>\n    </tr>\n    <tr>\n      <td>PortfolioHorizon</td>\n      <td>18</td>\n      <td>-4261.180163</td>\n    </tr>\n    <tr>\n      <td>Age</td>\n      <td>19</td>\n      <td>-4138.979040</td>\n    </tr>\n    <tr>\n      <td>ClientInvestmentHorizon</td>\n      <td>20</td>\n      <td>-4107.523616</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "from entropy_selection_class import dataframe_ext\n",
    "from entropy_RANK import RANK\n",
    "dataframe = df.sample(100)\n",
    "RANK(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SRANK(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bitbaseconda06b1561953f74f33a9fd63842c0f7dcf",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}